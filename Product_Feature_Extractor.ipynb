{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpT-o63Xdq_a"
      },
      "outputs": [],
      "source": [
        "# Install required libraries for PyTorch and Hugging Face Transformers\n",
        "!pip install torch torchvision torchaudio transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from collections import defaultdict, Counter\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Download sentence tokenizer model\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "id": "7zzU_Z5teLqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload CSV file from local system\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Read the uploaded CSV and keep only relevant columns\n",
        "df = pd.read_csv(next(iter(uploaded)))\n",
        "df = df[['productId', 'Title', 'Text']].dropna()\n"
      ],
      "metadata": {
        "id": "w5HRxdT_eODH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to split review text into individual sentences\n",
        "def split_into_sentences(review):\n",
        "    return sent_tokenize(review)\n"
      ],
      "metadata": {
        "id": "dj8Pe_yLeQVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Hugging Face sentiment analysis pipeline\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# Function to classify each sentence as positive or negative\n",
        "def get_sentiment(sentences):\n",
        "    pos, neg = [], []\n",
        "    for sentence in sentences:\n",
        "        result = sentiment_analyzer(sentence)[0]\n",
        "        label = result['label'].lower()\n",
        "        if label == 'positive':\n",
        "            pos.append(sentence)\n",
        "        elif label == 'negative':\n",
        "            neg.append(sentence)\n",
        "    return pos, neg\n"
      ],
      "metadata": {
        "id": "5pynjz9leS1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply sentiment analysis to each review's sentences\n",
        "df[['pos_sents', 'neg_sents']] = df['Text'].apply(\n",
        "    lambda x: pd.Series(get_sentiment(split_into_sentences(x)))\n",
        ")\n"
      ],
      "metadata": {
        "id": "8iKXzObFeU63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load FLAN-T5 tokenizer and model for feature extraction\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n"
      ],
      "metadata": {
        "id": "uPcqas_heX_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract short product features using FLAN-T5\n",
        "def extract_features(sentences):\n",
        "    features = []\n",
        "    for sentence in sentences:\n",
        "        prompt = f\"\"\"\n",
        "Extract short product features like 'battery life', 'design', 'price', 'smell' from the sentence below.\n",
        "Avoid opinions, full sentences, names, or reviews.\n",
        "\n",
        "Example 1:\n",
        "Sentence: \"The design is beautiful and the battery life lasts all day.\"\n",
        "Features: design, battery life\n",
        "\n",
        "Example 2:\n",
        "Sentence: \"It’s too expensive and doesn’t clean well.\"\n",
        "Features: price, cleaning performance\n",
        "\n",
        "Sentence: \"{sentence}\"\n",
        "Features:\"\"\"\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
        "        outputs = model.generate(**inputs, max_length=64)\n",
        "        result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        # Extract clean features and convert to lowercase\n",
        "        features += [f.strip().lower() for f in result.split(',') if f.strip()]\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "zAym4FFCeaCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply feature extraction on positive and negative sentences\n",
        "df['pos_features'] = df['pos_sents'].apply(extract_features)\n",
        "df['neg_features'] = df['neg_sents'].apply(extract_features)\n"
      ],
      "metadata": {
        "id": "NELfeOavedKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate features per product using a summary dictionary\n",
        "summary = defaultdict(lambda: {'title': '', 'pos': [], 'neg': []})\n",
        "\n",
        "# Loop through each row to group features by productId\n",
        "for _, row in df.iterrows():\n",
        "    pid = row['productId']\n",
        "    summary[pid]['title'] = row['Title']\n",
        "    summary[pid]['pos'] += row['pos_features']\n",
        "    summary[pid]['neg'] += row['neg_features']\n"
      ],
      "metadata": {
        "id": "fWV47DmCefaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For each product, find the top 3 positive and negative features\n",
        "for pid, feats in summary.items():\n",
        "    pos_top = [f for f, _ in Counter(feats['pos']).most_common(3)]\n",
        "    neg_top = [f for f, _ in Counter(feats['neg']).most_common(3)]\n",
        "\n",
        "    # Print the final summarized output\n",
        "    print(f\"Product: {feats['title']}\")\n",
        "    print(f\"  Most Appreciated Features: {', '.join(pos_top) or 'None'}\")\n",
        "    print(f\"  Least Appreciated Features: {', '.join(neg_top) or 'None'}\\n\")\n"
      ],
      "metadata": {
        "id": "9LjC_WA7ehzs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}